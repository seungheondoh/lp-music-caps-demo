<!DOCTYPE html>
<html>
    
    <head>
        <meta charSet="UTF-8" />
        <title>SeungHeon Doh | MIR, ML/DL Researcher</title>
        <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ¹</text></svg>"></link>
        <meta httpEquiv="x-ua-compatible" content="ie=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <meta name="robots" content="index, follow, noodp" />
        <meta name="googlebot" content="index, follow" />
        <meta name="google" content="notranslate" />
        <meta name="format-detection" content="telephone=no" />
        <title>SeungHeonDoh</title>
    </head>
    <style>
        header{        
            padding-top: 1.91rem;
        }
        header a{
            color: gray !important;
            text-decoration: none;
        }
        h1, h2, h3, h4, h5, h6 {
            font-family: "helvetica";
            margin-bottom: 1.01rem;
        }

        p{
            margin-bottom: 10px;
            line-height: 1.7;
        }
        small{
            font-size: 0.8rem;
        }
        b{
            color: blue;
        }
        h1 {
            font-size: 5rem;
            line-height: 1.15;
            }

        h2 {
            font-size: 4rem;
            line-height: 1.11;
        }

        h3 {
            font-size: 2rem;
            line-height: 1.74;
        }

        h4 {
            font-size: 1.4rem;
            line-height: 1.39;
        }

        h5 {
            font-size: 1.2rem;
            line-height: 1.56;
            margin-bottom: 0.5em;
        }

        h1, h2, h3, h4, h5, h6 {
            line-height: 1.56;
            margin-bottom: 1.01rem;
        }

        .main table {
            display: inline-table;
        }
        table {
            table-layout:fixed;
            width: 100%;
            overflow: hidden;
        }
        #player{
            width: 100%;
        }
        img, svg {
            max-width: 100%;
            height: auto;
        }

        .blog_contents{
            margin-bottom: 1rem;
        }

        .footer{
            height: 50px;
            background-color: white;
        }

        .wrapper {
            max-width: 1920px;
            margin: auto;
            padding-left: 20rem;
            padding-right: 20rem;
            }
        @media(max-width: 1700px){
            .wrapper {
                padding-left: 8rem;
                padding-right: 8rem;
            }
            }

        @media(max-width: 1199px){
            .wrapper {
            padding-left: 5rem;
            padding-right: 5rem;
            }
        }

        @media(max-width: 575px){
            .wrapper {
            padding-left: 1.25rem;
            padding-right: 1.25rem;
            }
        }
    </style>

    <body style="background-color: #f8f8f8;">
        <header id="header" class="site-header">
            <div class="wrapper">
                <a 
                    title="nav"
                    class="btn btn-link transform-scale-h border-0 p-0"
                    href="https://seungheondoh.github.io/#/">Home</a>
            </div>
        </header>
    
        <main id="main" class="site-main">
            <div class="wrapper">
                <h3>LP-MusicCaps: LLM-Based Pseudo Music Captioning</h3>
                    <pre><code>LP-MusicCaps: LLM-Based Pseudo Music Captioning, ISMIR 2023 (to appear) - SeungHeon Doh, Keunwoo Choi, Jongpil Lee, Juhan Nam
                    </code></pre>
                <!-- <li><a href="">Paper on Arxiv</a>(will be updated)</li> -->
                <li><a href="#">Paper on Arxiv</a></li>
                <li><a href="#">Implementation Code</a></li>
                <li><a href="#">Pre-trained model on Huggingface</a></li>
                <li><a href="#">Pre-trained model on Zenodo</a></li>
            </ul>

            <h4>Abstract</h4>
            <p>
                Automatic music captioning, which generates natural language descriptions for given music tracks, holds significant potential for enhancing the understanding and organization of large volumes of musical data. Despite its importance, researchers face challenges due to the costly and time-consuming collection process of existing music-language datasets, which are limited in size. 
                To address this data scarcity issue, we propose the use of large language models (LLMs) to artificially generate the description sentences from large-scale tag datasets. This results in approximately 2.2M captions paired with 0.5M audio clips. We term it {L}arge Language Model based {P}seudo music caption dataset, shortly, {LP-MusicCaps}. We conduct a systemic evaluation of the large-scale music captioning dataset with various quantitative evaluation metrics used in the field of natural language processing as well as human evaluation. In addition, we trained a transformer-based music captioning model with the dataset and evaluated it under zero-shot and transfer-learning settings. The results demonstrate that our proposed approach outperforms the supervised baseline model.

            </p>
            <img class="blog_contents" src="assets/img/main.png" alt="text_to_music"/> 
            <p>
            Will be updated
            </p>
        </main>
        <div class="footer"></div>
            </div>
    </body>
</html>
